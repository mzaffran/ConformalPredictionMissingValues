{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imputation as imp\n",
    "import generation as gen\n",
    "import prediction\n",
    "import utils\n",
    "import files\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_name = ['meps_19', 'bio', 'concrete', 'bike']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_sizes = {'meps_19': {'train': 1000, 'cal': 500, 'test_pattern': 100},\n",
    "                  'meps_20': {'train': 1000, 'cal': 500, 'test_pattern': 100},\n",
    "                  'meps_21': {'train': 1000, 'cal': 500, 'test_pattern': 100},\n",
    "                  'bio': {'train': 1000, 'cal': 500, 'test_pattern': 100},\n",
    "                  'concrete': {'train': 630, 'cal': 200, 'test_pattern': 100},\n",
    "                  'bike': {'train': 1000, 'cal': 500, 'test_pattern': 100}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rep = 100\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_missing = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation = 'iterative_ridge'\n",
    "\n",
    "methods = ['QR', 'QR_TrainCal', 'CQR', 'CQR_Masking_Cal']\n",
    "basemodels = ['NNet']\n",
    "masks = ['Yes']\n",
    "protections = ['No']\n",
    "subsets = [False, True]\n",
    "\n",
    "cores = 1\n",
    "\n",
    "params_basemodel = {'cores':cores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_path = \"./data/cqr_datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in tqdm(datasets_name):\n",
    "    \n",
    "    df, target, var_missing = datasets.GetDataset(dataset_name, dataset_base_path)\n",
    "    \n",
    "    params_missing = {}\n",
    "    params_missing['var_missing'] = var_missing\n",
    "    params_missing['prob_missing'] = prob_missing\n",
    "    \n",
    "    d = df.shape[1]-1\n",
    "    \n",
    "    if dataset_name == 'concrete':\n",
    "        nb_sample_pattern = datasets_sizes[dataset_name]['test_pattern']\n",
    "        params_test = {'iid':{'test_size': 200}, 'fixed_nb_sample_pattern':{'nb_sample_pattern': nb_sample_pattern}}\n",
    "    else:\n",
    "        nb_sample_pattern = datasets_sizes[dataset_name]['test_pattern']\n",
    "        params_test = {'iid':{'test_size': 2000}, 'fixed_nb_sample_pattern':{'nb_sample_pattern': nb_sample_pattern}}\n",
    "    params_test = gen.process_test(params_test, d=d, params_missing=params_missing)\n",
    "    \n",
    "    max_test_size = np.max(params_test['test_size'])\n",
    "    \n",
    "    train_size = datasets_sizes[dataset_name]['train']\n",
    "    cal_size = datasets_sizes[dataset_name]['cal']\n",
    "\n",
    "    name = files.get_name_data(train_size, cal_size, params_test, \n",
    "                               dataset=dataset_name, params_missing=params_missing, seed=n_rep)\n",
    "    \n",
    "    if os.path.isfile('data/'+name+'.xz'):\n",
    "        print('data found')\n",
    "        data = files.load_file('data', name, 'xz')\n",
    "    else:\n",
    "        print('data not found')\n",
    "        X, X_missing, M, Y = gen.generate_multiple_real_data_MCAR(df, target, train_size=train_size, \n",
    "                                                                  cal_size=cal_size, params_test=params_test,\n",
    "                                                                  params_missing=params_missing, seed_max=n_rep)\n",
    "        data = {'X': X, 'X_missing': X_missing, 'M': M,'Y': Y}\n",
    "        files.write_file('data', name, 'xz', data)\n",
    "        \n",
    "    name_imputed = files.get_name_data_imputed(train_size, cal_size, params_test, imputation=imputation,\n",
    "                                               dataset=dataset_name, params_missing=params_missing, seed=n_rep)\n",
    "\n",
    "    if os.path.isfile('data/'+name_imputed+'.pkl'):\n",
    "        print('imputation found')\n",
    "        X_imp = files.load_file('data', name_imputed, 'pkl')\n",
    "    else:\n",
    "        print('imputation not found')\n",
    "        if imputation == 'complete':\n",
    "            X_imp = data['X']\n",
    "        else:\n",
    "            X_imp = imp.impute(data, imputation)\n",
    "        files.write_file('data', name_imputed, 'pkl', X_imp)\n",
    "    data_imputed = {'X': data['X'], 'X_missing': data['X_missing'], 'X_imp': X_imp, 'M': data['M'],'Y': data['Y']}\n",
    "\n",
    "    \n",
    "    results, methods_ran = prediction.run_experiments(data_imputed, alpha=alpha, methods=methods,\n",
    "                                                      basemodels=basemodels, params_basemodel=params_basemodel,\n",
    "                                                      masks=masks, protections=protections, \n",
    "                                                      subsets=subsets, imputation=imputation)\n",
    "\n",
    "    for method in methods_ran:\n",
    "        name_dir, name_method = files.get_name_results(method, train_size, cal_size, n_rep, \n",
    "                                                       dataset=dataset_name, imputation=imputation,\n",
    "                                                       params_missing=params_missing)\n",
    "        \n",
    "        results_method = results[method]\n",
    "        files.write_file('results/'+name_dir, name_method, 'xz', results_method)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
